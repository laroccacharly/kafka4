FROM apache/spark:3.5.0-scala2.12-java11-python3-ubuntu

WORKDIR /app

USER root

# Install Maven and librdkafka in a single layer
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    maven \
    librdkafka-dev \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Copy files and set up dependencies in a single layer
COPY pom.xml requirements_consumer.txt ./
RUN mvn dependency:copy-dependencies -DoutputDirectory=$SPARK_HOME/jars/ && \
    pip3 install --no-cache-dir -r requirements_consumer.txt && \
    mkdir -p data checkpoints && \
    chown -R spark:spark .

# Copy only the necessary Python files
COPY consume.py .

USER spark

CMD ["python3", "consume.py"]